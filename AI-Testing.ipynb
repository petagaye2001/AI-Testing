{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad9d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import pandas as pd\n",
    "\n",
    "\n",
    "# Define a function to remove illegal characters\n",
    "def remove_illegal_characters(s):\n",
    "    illegal_char_pattern = re.compile(r'[\\000-\\010]|[\\013-\\014]|[\\016-\\037]')\n",
    "    if isinstance(s, str):\n",
    "        return illegal_char_pattern.sub(\"\", s)\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "file_path = os.path.join(os.path.expanduser('~'), 'Desktop', 'March032024Opportunities.csv')\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='latin-1')\n",
    "    print(\"CSV file read successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the following:\")\n",
    "    print(f\"- File path accuracy: {file_path}\")\n",
    "    print(f\"- File existence: Check if the file exists at the specified path.\")\n",
    "    print(f\"- Current working directory: {os.getcwd()}\")\n",
    "    print(f\"- File permissions: Verify your script has read access to the file.\")\n",
    "    print(f\"- File encoding: If the file has a different encoding, specify it using the 'encoding' argument in pd.read_csv().\")\n",
    "else:\n",
    "    keywords = [\n",
    "        \"project management\", \"data analytics\", \"artificial intelligence\", \"dev ops\", \"product management\",\n",
    "        \"project support\", \"technical services\", \"administrative services\", \"solicitation\", \"set aside\", \"women-owned\",\n",
    "        \"small business\",\n",
    "    ]\n",
    "\n",
    "    def contains_any_keyword(description):\n",
    "        description_str = str(description).lower()\n",
    "        return any(keyword in description_str for keyword in keywords)\n",
    "\n",
    "    columns_of_interest = [\n",
    "        \"Title\", \"Description\", \"Current Response Date\", \"Contract Opportunity Type\", \"Set Aside\", \"POC Information\",\n",
    "    ]\n",
    "\n",
    "    # Define df_filtered here to ensure it's always defined before use\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    missing_columns = [col for col in columns_of_interest if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Warning: Missing columns in DataFrame - {missing_columns}\")\n",
    "        df_filtered = df_filtered.drop(columns=missing_columns, errors='ignore')\n",
    "    else:\n",
    "        df_filtered = df_filtered[columns_of_interest]\n",
    "\n",
    "    for col in df_filtered.select_dtypes(include=['object']).columns:\n",
    "        df_filtered.loc[:, col] = df_filtered.loc[:, col].apply(remove_illegal_characters)\n",
    "\n",
    "    filtered_df = df_filtered[df_filtered['Description'].apply(contains_any_keyword)]\n",
    "    print(filtered_df['Title'])\n",
    "\n",
    "    # Now try saving the DataFrame to Excel again\n",
    "    filtered_df.to_excel('Marchfiltered_Titles_with_keywords.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you already have the 'contains_any_keyword' function defined\n",
    "\n",
    "# Step 1: Count keyword occurrences\n",
    "# This dictionary will hold our keyword frequencies\n",
    "keyword_frequencies = {keyword: 0 for keyword in keywords}\n",
    "\n",
    "for description in df['Description'].dropna():\n",
    "    description_str = description.lower()\n",
    "    for keyword in keywords:\n",
    "        if keyword in description_str:\n",
    "            keyword_frequencies[keyword] += 1\n",
    "\n",
    "# Step 2: Visualization\n",
    "# Bar Chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(keyword_frequencies.keys(), keyword_frequencies.values(), color='skyblue')\n",
    "plt.xlabel('Keywords')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title('Keyword Frequency in Opportunities')\n",
    "plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n",
    "plt.show()\n",
    "\n",
    "# Word Cloud\n",
    "wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate_from_frequencies(keyword_frequencies)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Remove axis for better visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"A project management opportunity...\",\n",
    "        \"Analyze data trends...\",\n",
    "        \"...AI to make improvements...\",\"...AI to tag data...\",\n",
    "        \"Streamline CI/CD pipelines...\"\n",
    "    ],\n",
    "    \"Set Aside\": [1, 0, 1, 0,1]  # 1 for small business set-aside, 0 otherwise\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split data into features and target\n",
    "X = df['Description']\n",
    "y = df['Set Aside']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a machine learning pipeline that includes TF-IDF vectorization and a logistic regression model\n",
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Preprocess the Data and Feature Engineering\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming 'df' is your DataFrame with 'Description' and 'Set Aside' columns ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be7b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Your Data into Training and Testing Sets\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = df['Description']  # Features\n",
    "y = df['Set Aside']    # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89270faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE AND TRAINI THE MODEL \n",
    "\n",
    "# Create a machine learning pipeline\n",
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743348d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE THE MODEL \n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# You can also print the confusion matrix to see how well the model is performing\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005866a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PREDICTIONS ON TEH NEW DATA \n",
    "\n",
    "# Example of predicting a new description\n",
    "new_descriptions = [\n",
    "    \"An opportunity for small businesses to engage in IT development projects.\",\n",
    "    \"Large scale construction project requiring significant capital investment.\"\n",
    "]\n",
    "predictions = pipeline.predict(new_descriptions)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a82c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize mdoe performance\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dummy metrics for illustration\n",
    "accuracy = 0.85\n",
    "precision = 0.80\n",
    "recall = 0.75\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = [[50, 10], [15, 25]]\n",
    "\n",
    "# Summarize metrics in a string\n",
    "summary = f\"\"\"\n",
    "Model Performance Summary:\n",
    "- Accuracy: {accuracy * 100:.2f}%\n",
    "- Precision: {precision * 100:.2f}%\n",
    "- Recall: {recall * 100:.2f}%\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize \n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
